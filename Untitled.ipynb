{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import SGD\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer function for image preprocessing\n",
    "transforms_func = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# mnist train_set\n",
    "mnist_train = MNIST('./data',train=True,download=True,transform=transforms_func)\n",
    "\n",
    "# mnist test_set\n",
    "mnist_test = MNIST('./data',train=False,transform=transforms_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.9*mnist_train.__len__())\n",
    "valid_len = mnist_train.__len__() - train_len\n",
    "mnist_train, mnist_valid = torch.utils.data.random_split(mnist_train, lengths=[train_len, valid_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t54000\n",
      "- Validation-set:\t6000\n",
      "- Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(mnist_train.__len__()))\n",
    "print(\"- Validation-set:\\t{}\".format(mnist_valid.__len__()))\n",
    "print(\"- Test-set:\\t\\t{}\".format(mnist_test.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = mnist_train.train_data[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = mnist_train.train_labels[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = nn.Linear(784,10)\n",
    "        self.init_weights_and_bias()\n",
    "#         self.weight = Parameter(torch.zeros((784, 10),dtype=torch.float32,requires_grad=True))\n",
    "#         self.bias = Parameter(torch.zeros((10),dtype=torch.float32,requires_grad=True))\n",
    "    \n",
    "    def init_weights_and_bias(self):\n",
    "        torch.nn.init.xavier_normal_(self.fc.weight)\n",
    "        torch.nn.init.zeros_(self.fc.bias)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "#         out = torch.addmm(self.bias, x, self.weight)\n",
    "        out = self.fc(x)\n",
    "        out = F.log_softmax(out,1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,train_loader,valid_loader,optimizer,epoch):\n",
    "    model.train()\n",
    "    for i,(data,target) in tqdm_notebook(enumerate(train_loader),total=train_loader.__len__()):\n",
    "        data = torch.reshape(data,(-1,784))\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "#         set_trace()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    test(model,device,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(data, target) in tqdm_notebook(enumerate(test_loader),total=test_loader.__len__()):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = torch.reshape(data,(-1,784))\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(mnist_train,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(mnist_valid,batch_size=1024,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_test,batch_size=1024,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel().to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "optimizer = SGD(model.parameters(),lr=0.5)\n",
    "for epoch in range(epochs):\n",
    "        train(model,'cpu',train_loader,valid_loader,optimizer,epoch)\n",
    "        test(model,'cpu',test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights():\n",
    "    # Get the values for the weights from the TensorFlow variable.\n",
    "    w = model.get_weights()\n",
    "    w = w.numpy()\n",
    "    img_shape = (28,28)\n",
    "    \n",
    "    # Get the lowest and highest values for the weights.\n",
    "    # This is used to correct the colour intensity across\n",
    "    # the images so they can be compared with each other.\n",
    "    w_min = np.min(w)\n",
    "    w_max = np.max(w)\n",
    "\n",
    "    # Create figure with 3x4 sub-plots,\n",
    "    # where the last 2 sub-plots are unused.\n",
    "    fig, axes = plt.subplots(3, 4)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only use the weights for the first 10 sub-plots.\n",
    "        if i<10:\n",
    "            # Get the weights for the i'th digit and reshape it.\n",
    "            # Note that w.shape == (img_size_flat, 10)\n",
    "            image = w[:, i].reshape(img_shape)\n",
    "\n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "        # Remove ticks from each sub-plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors():\n",
    "    # Use TensorFlow to get a list of boolean values\n",
    "    # whether each test-image has been correctly classified,\n",
    "    # and a list for the predicted class of each image.\n",
    "    #correct, cls_pred = session.run([correct_prediction, y_pred_cls],\n",
    "                                    #feed_dict=feed_dict_test)\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    cls_pred,incorrect = get_incorrect_samples(model,'cpu',test_loader)\n",
    "    #incorrect = ~incorrect\n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = mnist_test.test_data[incorrect].detach().numpy()\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = mnist_test.test_labels[incorrect].detach().numpy()\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrect_samples(model, device, test_loader):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    correct = []\n",
    "    with torch.no_grad():\n",
    "        for i,(data, target) in tqdm_notebook(enumerate(test_loader),total=test_loader.__len__()):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            correct.extend(target)\n",
    "            data = torch.reshape(data,(-1,784))\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            prediction.extend(pred.squeeze())\n",
    "    out = torch.eq(torch.Tensor(prediction).type(torch.FloatTensor),torch.Tensor(correct).type(torch.FloatTensor))\n",
    "    return np.asarray(prediction),out.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0590, -0.0213,  0.1101,  ..., -0.1071, -0.0308, -0.0339],\n",
       "         [ 0.0345,  0.0200,  0.0790,  ..., -0.0147, -0.0371, -0.0519],\n",
       "         [ 0.0305, -0.0293,  0.0666,  ..., -0.1485, -0.0646, -0.0241],\n",
       "         ...,\n",
       "         [-0.0134, -0.0260, -0.0246,  ..., -0.0028,  0.0191, -0.0078],\n",
       "         [ 0.0059,  0.0380,  0.0092,  ..., -0.0378, -0.0561, -0.0341],\n",
       "         [ 0.0601,  0.1145, -0.0237,  ..., -0.0166,  0.0450, -0.0317]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
