{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm_notebook,trange\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer function for image preprocessing\n",
    "transforms_func = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# mnist train_set\n",
    "mnist_train = MNIST('./data',train=True,download=True,transform=transforms_func)\n",
    "\n",
    "# mnist test_set\n",
    "mnist_test = MNIST('./data',train=False,transform=transforms_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.9*mnist_train.__len__())\n",
    "valid_len = mnist_train.__len__() - train_len\n",
    "mnist_train, mnist_valid = torch.utils.data.random_split(mnist_train, lengths=[train_len, valid_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t54000\n",
      "- Validation-set:\t6000\n",
      "- Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(mnist_train.__len__()))\n",
    "print(\"- Validation-set:\\t{}\".format(mnist_valid.__len__()))\n",
    "print(\"- Test-set:\\t\\t{}\".format(mnist_test.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of pixels in each dimension of an image.\n",
    "img_size = (28,28)\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 784\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (28,28)\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0bf48f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = mnist_train.dataset.train_data[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = mnist_train.dataset.train_labels[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=(5,5),stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=36,kernel_size=(5,5),stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=576,out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128,out_features=10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = F.relu(F.max_pool2d(self.conv1(x),kernel_size=(2,2)))\n",
    "        out = F.relu(F.max_pool2d(self.conv2(out),kernel_size=(2,2)))\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.log_softmax(self.fc2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,train_loader,optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for data,target in tqdm_notebook(train_loader,total=train_loader.__len__()):\n",
    "        #data = torch.reshape(data,(-1,784))\n",
    "        import pdb;pdb.set_trace()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(train_loader.dataset),100. * correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(data, target) in tqdm_notebook(enumerate(test_loader),total=test_loader.__len__()):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "train_loader = DataLoader(mnist_train,batch_size=64,shuffle=True,**kwargs)\n",
    "test_loader = DataLoader(mnist_test,batch_size=1024,shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0fabd0862047a6aaaaa93d6e720504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=844), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-19-aaa18e78144e>(7)train()\n",
      "-> data, target = data.to(device), target.to(device)\n",
      "(Pdb) data\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "(Pdb) data.shape\n",
      "torch.Size([64, 1, 28, 28])\n",
      "(Pdb) exit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-26f37b968ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-aaa18e78144e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#data = torch.reshape(data,(-1,784))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-aaa18e78144e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#data = torch.reshape(data,(-1,784))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "        train(model,device,train_loader,optimizer)\n",
    "        test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
